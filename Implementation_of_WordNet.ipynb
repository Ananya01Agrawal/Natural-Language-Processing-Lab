{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD-JOa_P9ngV",
        "outputId": "de273beb-43f6-4fa9-f41a-339e0be46914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEd-H7fc90DM",
        "outputId": "463bb38c-7260-4817-95ef-d2c615bf7229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  WordNet is a lexical database of the English language, which groups words into sets of synonyms called synsets, provides short, general definitions, and records the various semantic relations between these synonym sets.\n",
        "#  It's often used in natural language processing tasks like semantic analysis, information retrieval, and text mining."
      ],
      "metadata": {
        "id": "PAvtnuIYpS3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Example usage of WordNet\n",
        "word = \"car\"\n",
        "\n",
        "# Get synsets for the word\n",
        "synsets = wordnet.synsets(word)\n",
        "\n",
        "# Print the synsets\n",
        "for synset in synsets:\n",
        "    print(\"Synset Name:\", synset.name())\n",
        "    print(\"POS Tag:\", synset.pos())\n",
        "    print(\"Definition:\", synset.definition())\n",
        "    print(\"Examples:\", synset.examples())\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzI1FHgL94Ez",
        "outputId": "54a5aa41-95a6-46a9-abcc-cf97e89ddd6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset Name: car.n.01\n",
            "POS Tag: n\n",
            "Definition: a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
            "Examples: ['he needs a car to get to work']\n",
            "\n",
            "Synset Name: car.n.02\n",
            "POS Tag: n\n",
            "Definition: a wheeled vehicle adapted to the rails of railroad\n",
            "Examples: ['three cars had jumped the rails']\n",
            "\n",
            "Synset Name: car.n.03\n",
            "POS Tag: n\n",
            "Definition: the compartment that is suspended from an airship and that carries personnel and the cargo and the power plant\n",
            "Examples: []\n",
            "\n",
            "Synset Name: car.n.04\n",
            "POS Tag: n\n",
            "Definition: where passengers ride up and down\n",
            "Examples: ['the car was on the top floor']\n",
            "\n",
            "Synset Name: cable_car.n.01\n",
            "POS Tag: n\n",
            "Definition: a conveyance for passengers or freight on a cable railway\n",
            "Examples: ['they took a cable car to the top of the mountain']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "XeUIXplADhvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example large dataset (list of sentences)\n",
        "large_dataset = [\n",
        "    \"This is the first sentence in the dataset.\",\n",
        "    \"And this is the second sentence.\",\n",
        "    \"Another sentence follows.\",\n",
        "    \"Yet another sentence comes after that.\"\n",
        "]"
      ],
      "metadata": {
        "id": "4pr_qfEW-Lgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize WordNet lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "gVhAHI0C-PJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform WordNet operations on a sentence\n",
        "def perform_wordnet_operations(sentence):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Example WordNet operation: finding synonyms\n",
        "    synonyms = []\n",
        "    for token in lemmatized_tokens:\n",
        "        synsets = wordnet.synsets(token)\n",
        "        for synset in synsets:\n",
        "            synonyms.extend(synset.lemma_names())\n",
        "\n",
        "    return synonyms"
      ],
      "metadata": {
        "id": "rFGVdGPPDpWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USIX6r7QD9lP",
        "outputId": "e7fb6599-6b4b-4f90-ced9-4c74188fd31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the dataset and perform WordNet operations on each sentence\n",
        "for sentence in large_dataset:\n",
        "    print(\"Sentence:\", sentence)\n",
        "    synonyms = perform_wordnet_operations(sentence)\n",
        "    print(\"Synonyms:\", synonyms)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIC1SioJDtPx",
        "outputId": "aefc3933-852a-423e-cdb4-7ab75e054a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: This is the first sentence in the dataset.\n",
            "Synonyms: ['be', 'be', 'be', 'exist', 'be', 'be', 'equal', 'be', 'constitute', 'represent', 'make_up', 'comprise', 'be', 'be', 'follow', 'embody', 'be', 'personify', 'be', 'be', 'live', 'be', 'cost', 'be', 'first', 'number_one', 'first', 'number_one', 'number_1', 'beginning', 'commencement', 'first', 'outset', 'get-go', 'start', 'kickoff', 'starting_time', 'showtime', 'offset', 'first_base', 'first', 'first', 'first-class_honours_degree', 'first_gear', 'first', 'low_gear', 'low', 'first', 'first', '1st', 'inaugural', 'initiative', 'initiatory', 'first', 'maiden', 'beginning', 'first', 'first', 'foremost', 'world-class', 'first', 'first', 'firstly', 'foremost', 'first_of_all', 'first_off', 'first', 'for_the_first_time', 'first', 'foremost', 'first', 'sentence', 'conviction', 'judgment_of_conviction', 'condemnation', 'sentence', 'prison_term', 'sentence', 'time', 'sentence', 'condemn', 'doom', 'inch', 'in', 'indium', 'In', 'atomic_number_49', 'Indiana', 'Hoosier_State', 'IN', 'in', 'in', 'in', 'in', 'inwards', 'inward']\n",
            "\n",
            "Sentence: And this is the second sentence.\n",
            "Synonyms: ['be', 'be', 'be', 'exist', 'be', 'be', 'equal', 'be', 'constitute', 'represent', 'make_up', 'comprise', 'be', 'be', 'follow', 'embody', 'be', 'personify', 'be', 'be', 'live', 'be', 'cost', 'be', 'second', 'sec', 's', 'moment', 'mo', 'minute', 'second', 'bit', 'second_base', 'second', 'moment', 'minute', 'second', 'instant', 'second', 'second', 'arcsecond', 'second', 'second', 'secondment', 'endorsement', 'indorsement', 'second_gear', 'second', 'irregular', 'second', 'second', 'back', 'endorse', 'indorse', 'second', 'second', '2nd', '2d', 'second', 'second', 'secondly', 'sentence', 'conviction', 'judgment_of_conviction', 'condemnation', 'sentence', 'prison_term', 'sentence', 'time', 'sentence', 'condemn', 'doom']\n",
            "\n",
            "Sentence: Another sentence follows.\n",
            "Synonyms: ['another', 'some_other', 'sentence', 'conviction', 'judgment_of_conviction', 'condemnation', 'sentence', 'prison_term', 'sentence', 'time', 'sentence', 'condemn', 'doom', 'follow', 'postdate', 'follow', 'follow', 'fall_out', 'follow', 'travel_along', 'comply', 'follow', 'abide_by', 'follow', 'come_after', 'follow', 'conform_to', 'follow', 'adopt', 'follow', 'espouse', 'follow', 'take_after', 'follow', 'trace', 'follow', 'watch', 'observe', 'follow', 'watch_over', 'keep_an_eye_on', 'succeed', 'come_after', 'follow', 'play_along', 'accompany', 'follow', 'keep_up', 'keep_abreast', 'follow', 'come', 'follow', 'follow', 'follow', 'be', 'follow', 'surveil', 'follow', 'survey', 'pursue', 'follow', 'follow', 'stick_to', 'stick_with', 'follow']\n",
            "\n",
            "Sentence: Yet another sentence comes after that.\n",
            "Synonyms: ['yet', 'so_far', 'thus_far', 'up_to_now', 'hitherto', 'heretofore', 'as_yet', 'yet', 'til_now', 'until_now', 'even', 'yet', 'still', 'yet', 'in_time', 'so_far', 'yet', 'however', 'nevertheless', 'withal', 'still', 'yet', 'all_the_same', 'even_so', 'nonetheless', 'notwithstanding', 'another', 'some_other', 'sentence', 'conviction', 'judgment_of_conviction', 'condemnation', 'sentence', 'prison_term', 'sentence', 'time', 'sentence', 'condemn', 'doom', 'semen', 'seed', 'seminal_fluid', 'ejaculate', 'cum', 'come', 'come', 'come_up', 'arrive', 'get', 'come', 'come', 'come', 'come', 'follow', 'come', 'issue_forth', 'come', 'hail', 'come', 'come', 'come', 'come', 'fall', 'come', 'come', 'total', 'number', 'add_up', 'come', 'amount', 'come', 'add_up', 'amount', 'come', 'come_in', 'occur', 'come', 'derive', 'come', 'descend', 'do', 'fare', 'make_out', 'come', 'get_along', 'come', 'come', 'after', 'subsequently', 'later', 'afterwards', 'afterward', 'after', 'later_on', 'after']\n",
            "\n"
          ]
        }
      ]
    }
  ]
}